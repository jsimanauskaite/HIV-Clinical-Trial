---
title: "Survival Analysis Project: HIV Clinical Trial"
author: "Juste Simanauskaite & Patricia Rivera"
geometry: margin=2cm
output: 
  pdf_document: 
    
    highlight: tango
    toc: true
    toc_depth: 6
    fig_width: 30
    fig_height: 15
    fig_crop: false
  html_document: default
---
# Introduction
  HIV (Human Immunodeficiency Virus) is a disease known as an immune system disorder, which causes severe destruction of white blood cells that are responsible for fighting infection. The presence of this disorder is a lead-in for a human to be more prone to infections and cancer diseases. AIDS is the final stage of HIV, which is not always developed in HIV patients. Zidovudine (AZT) is known as antiretroviral medication for prevention of HIV/AIDS, whereas lamuvidine (3TC) is an inhibitor medication that works in decreasing HIV and hepatitis B. Previously, it has been founded that three-drug combinations, in particular, with a previous exposure to AZT, have shown the most significant resulted in reducing HIV-1 RNA concentrations. Therefore, this study used indinavir sulfate (a synthetic antiviral agent that inhibits HIV protease activity) in combination with AZT and 3TC as well as variation of placebo treatments to determine the potency of triple drug therapy in the cases of  advanced HIV-1 patients. The study hypothesized that a three-drug combination, including a HIV-protease inhibitor and two nucleoside analogues (AZT and 3TC) would alter the progression of the HIV-1 disease. The study was successful in reaching significant data of the clinical superiority of a three-drug approach with inidavor over a treatment containing only a two-drug combination.

The current analysis of the data from a study conducted by Hammer et al. in 1997 considers the response variable to be *time*, which here describes the amount of time in days for the time of death, AIDS diagnosis, or the termination of the study. Another important variable used for the analysis is *censor*, which indicates the paarticipants of the study that survived till the termination of the study without dying or being diagnosed AIDS. The study explored the influence of the explanatory varibale *tx*. referring to the treatment group that was differentiated into: a control (placebo group) and a treatment group that included IDV (indinavir)
# Methods

The study was a randomized, double-blind, and a placebo-controlled trial that compared a three-drug treatment of indinavir (Crixivan), zidovudine (AZT) and lamivudine (3TC) with a two-drug treatment. Patients were selected based on the factor that they had no more than 200 CD4 cells per cubic millimetear at least 3 months prioir to AZT therapy. The patients had to be more than 16 years old, with a diagnostic documentation of HIV-1 infection, having no more than 1 week of prior lamuvidine treatment, and a Karnofsky score of at least 70.

The approved patients received 200mg of open-label zidovudine three times daily and 150mg of lamuvidine two times daily and were randomly assigned to a placebo or a treatment of 800mg of indinavir every eight hours.

Some modifications were made to the protocol. In October of 1996 prioir exposure to AZT was reduced to at least 3 months and permitted patients with no tolerance for this drug to enter the study with stavudine as a substitute.

Patients diagnosed with AIDS-defining events were offored an open-label assignment of the indinavir treatment with nor reveal of their initial treatment assignments. All of these cases had to be reviewed via a blind procedure by the study chair.

Follow ups were made at weeks 4,8, and 16 and every eight weeks afterwards. CD4 cell counts and Plasma HIV-1 RNA concentrations were measured twice at baseline and at weeks 4,8,24, and 40. 

The statistical analysis methods used to interpret results were Kaplan-Meier estimates, log-rank tests, and proportional hazards models. The p-values, estimates of treatment differences and 95% confidence intervals were not adjusted for repeated analysis.

The data and results have been reviewed again in 2019 and have been analyzed via statistic methhods such as Cox Proportional Hazards test, Kaplan-Meier estimates, Aalen model, Power analysis, and Schoenfeld residuals.
```{r global_options, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, fig.height=3, fig.width=5, 
                      fig.align="center")
library(tidyverse)
library(broom)
library(plyr)
library(survival)
library(survminer)
library(coxed)
library(ggplot2)
library(broom)


aids <- read.csv( "http://pages.pomona.edu/~jsh04747/courses/math150/AIDSdata.csv")
dim(aids)
summary(aids)

```
# Data-Set Analysis
The data set contains a sample size equal to 851 participants and 16 different variables. Out of these participants 782 were considered as uncensored data point, which indicates that these patients survived through the course of the study without diagnosis of AIDS and/or death. 69 were found to be censored meaning that either there was an occurence of death or AIDS diagnosis, out of which it is known that 20 patients died throughout the course of the study.


```{r}
#Survival Analysis 
#mutation of age
aids <- read.csv( "http://pages.pomona.edu/~jsh04747/courses/math150/AIDSdata.csv")
aids <- aids %>% 
  mutate(age = ifelse(age <= 20, "under20", 
                             ifelse(age <=30, "20-30",
                                    ifelse(age <= 40, "30-40",
                                           ifelse(age <=50, "40-50",
                                                 ifelse(age <=60, "50-60",
                                                        ifelse(age <=70, "60-70", 
                                                               "over70"))))))) %>%
  mutate(age = factor(age,
                       levels = c("under20", "20-30", "30-40","40-50", "50-60","60-70","over70")),  
         sex = ifelse(sex == 2, "male","female"))

aids <- aids %>% 
  mutate(cd4 = ifelse(cd4 <=50, "0-50", 
                             ifelse(cd4 <=100, "50-100",
                                    ifelse(cd4 <= 150, "100-150",
                                           ifelse(cd4 <=200, "150-200",
                                                 ifelse(cd4 <=250, "200-250",
                                                        ifelse(cd4 <=300, "300-350", "350+"))))))) 
```
Since there are many values of the explanatory variable *age* in the original data, we've decided to mutate the variable into age categories from under 20 to over 70 in increments of 10 years. Similar modifications have been made to the baseline *CD4* count, just in incrimennts of 50 up until 350+. Furthermore, we changed the labeling and representation of *sex* into "male" and "female" instead of "1" and "2" in the data.

```{r}
library(plotrix)
male<-sum(aids$sex=="male")
female<-sum(aids$sex=="female")
slices <- c(male, female) 
lbls <- c("Male","Female")
pct <- round(slices/sum(slices)*100)
df = data.frame(slices = pct,labels =  lbls)
sexplot<- ggplot(df,aes(x = factor(1),y=pct,  fill = labels)) +
         geom_bar(stat="identity", width = 1)+
        coord_polar(theta = "y")+
        theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_blank())
print(sexplot + ggtitle("Gender Distribution")+ 
        scale_fill_manual(values=c("#55DDE0", "#33658A",
                                   "#2F4858"))+
        labs(x = NULL, y = NULL, fill = NULL))

```
The Pie Chart represents the gender distribution in the sample, with 84% male and 16% female. This shows the potential for the data to not be able to correctly represent the difference of the data variance by gender, if there were to be one. Therefore, gender is something to look into in future data analysis.
```{r}
wnh<-sum(aids$raceth==1)
bnh<-sum(aids$raceth==2)
h<-sum(aids$raceth==3)
api<-sum(aids$raceth==4)
aian<-sum(aids$raceth==5)
oth<-sum(aids$raceth==6)
slices <- c(wnh,bnh,h,api,aian,oth) 
lbls <- c("White Non-Hispanic", "Black Non-Hispanic", "Hispanic","Asian, Pacific Islander", 
          "American Indian, Alaskan Native", "Other/unknown")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) 
lbls <- paste(lbls,"%",sep="") 
df = data.frame(slices = slices,labels =  lbls)

ethplot<- ggplot(df,aes(x = factor(1),y=slices,  fill = labels)) +
         geom_bar(stat="identity", width = 1)+
        coord_polar(theta = "y")+
        theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_blank())
print(ethplot + ggtitle("Race/Ethnicity Distribution among participants")+
        scale_fill_manual(values=c("#55DDE0", "#33658A",
                                   "#2F4858", "#F6AE2D", "#F26419", 
                                   "#999999"))+ labs(x = NULL, y = NULL,
                                                     fill = NULL))



```
The distribution of race/ethnicity shows that the greatest number of participants consists of white non-Hispanic identifying individuals, with black non-Hispanic following and Hispanic as the 3rd largest represented group.
```{r}
never<-sum(aids$ivdrug==1)
cur<-sum(aids$ivdrug==2)
prev<-sum(aids$ivdrug==3)
slices <- c(never,cur,prev) 
lbls <- c("Never", "Currently", "Previously")
pct <- round(slices/sum(slices)*100)
lbls <- paste(lbls, pct) 
lbls <- paste(lbls,"%",sep="") 
df = data.frame(slices = slices,labels =  lbls)
ivplot<- ggplot(df,aes(x = factor(1),y=slices,  fill = labels)) +
         geom_bar(stat="identity", width = 1)+
        coord_polar(theta = "y")+
        theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_blank())
print(ethplot + ggtitle("IV Drug Use History")+ 
        scale_fill_manual(values=c("#56ADE3", "#12358A", 
                                   "#F41288", "#F7BE6D", "#F26569",
                                   "#A65674"))+ 
        labs(x = NULL, y = NULL, fill = NULL))

```
From this chart we see that most of the participants (84%) have never used IV drugs, whereas 16% of participants have some type of history of usage and none of the participants reported to be currently using the drugs.

# Results

## Survival Analysis

### Kaplan-Meier Curves

The following graph is a representation of a Kaplan Meier Curve for all participants in the study, we can see that only a few participants dies or were diagnosed with AIDS during the study as the slope of the curve is not experiencing a high decrease.
```{r}

fit <- survfit(Surv(time,censor)~1, data = aids)
ggsurvplot(fit,data = aids,conf.int = FALSE) + ggtitle("Overall")


```

The following graph is a representation of the Kaplan-Meier survival probability based on the treatment indicator. In this case *tx=0* was the control group and *tx=1* the treatment group that was gived IDV. Already, we can see a tred in the graph that the control group shows a lower survival probability with time. According to the log-rank test, we see that the p-value for the test statistic is equal to 0.002 (<0.05), thus we can reject the null hypothesis that the two population survival functions are the same, and the alternative is accepted, which says that the survival curves are different. The Wilcoxon test also provides us with a small p-value of 0.002 , which again rejects the null and goes in agreement with our primary conclusion.

```{r}
fit1 <- survfit(Surv(time,censor)~tx, data = aids)
ggsurvplot(fit1,data = aids,conf.int = FALSE) + ggtitle("Treatment Indicator")

'Log-Rank'
survdiff(Surv(time,censor)~tx, data = aids, rho=0)
'Wilcoxon'
survdiff(Surv(time,censor)~tx, data = aids, rho=1)
```

```{r}
fit2 <- survfit(Surv(time,censor)~age, data = aids)
ggsurvplot(fit2,data = aids,conf.int = FALSE) + ggtitle("Age")

'Log-Rank'
survdiff(Surv(time,censor)~age, data = aids, rho=0)
'Wilcoxon'
survdiff(Surv(time,censor)~age, data = aids, rho=1)
```
The following graph is a representation of the Kaplan-Meier survival probability based on the Baseline CD4. Due to the close proximity of the curves it's harder to see the significance of the differences. However, according to the log-rank test, we see that the p-value for the test statistic is equal to 5e-07  (<0.05), thus we can reject the null hypothesis, The Wilcoxon test  again provides us with a small p-value of 5e-07, which again rejects the null and goes in agreement with our primary conclusion that the curves are significantly different.

```{r}
fit3 <- survfit(Surv(time,censor)~cd4, data = aids)
ggsurvplot(fit3,data = aids,conf.int = FALSE) + ggtitle("Baseline CD4 Count")

'Log-Rank'
survdiff(Surv(time,censor)~cd4, data = aids, rho=0)
'Wilcoxon'
survdiff(Surv(time,censor)~cd4, data = aids, rho=1)
```

The final explanatory variable we're investigating as a part of our model is the Karnofsky Performance Scale. The Kaplan-Meier curves for this variable present a higher amplitude of distributions across the survival scale. The p-values of both log-rank and the Wilcoxon Test again present with the same significant p-value of  5e-10  (<0.05), thus we can reject the null hypothesis of no difference between the curves and consider this a significant variable in the construction of our model.

```{r}
aids_fit_time_k <- survfit(Surv(time, censor) ~karnof  , data=aids)
ggsurvplot(aids_fit_time_k, data=aids,  conf.int = TRUE) +
  ggtitle("Karnofsky Performance Score")

'Log-Rank'
survdiff(Surv(time,censor)~karnof, data = aids, rho=0)
'Wilcoxon'
survdiff(Surv(time,censor)~karnof, data = aids, rho=1)

```

To decide what variables to use in our COX PH model, we can use backwards selection to determine what explanatory variables are most important to the model, along with the likelihood ratio test to compare differences in our models. Using time_d and censor_d as the response variables, we begin with the full model that includes the rest of the
variables (minus time and censor) as the explanatory variables. We remove the variable with the highest $p$ value first and create a new model without this variable. Using the likelihood ratio test between the two models, we then determine whether or not the variable added significance to the model. We continued this process until we arrived at the best model which uses *tx*, *karnof*, *cd4* and *age* as the explanatory variables.

```{r}
### COX PH MODEL USING BACKWARDS SELECTION ####
aids <- read.csv( "http://pages.pomona.edu/~jsh04747/courses/math150/AIDSdata.csv")

#full model
cp_full<- coxph(Surv(time_d,censor_d)~.-time -censor, data = aids)
cp_full$loglik
cp_full

#reduced model 1
cp_red1<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug, data=aids)
cp_red1$loglik
#cp_red1

#likelihood ratio test and p-value
s1 <- 2*(cp_full$loglik[2]-cp_red1$loglik[2])
1-pchisq(s1,1)


#reduced model 2
cp_red2<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv, data=aids)
cp_red2$loglik
#cp_red2

#likelihood ratio test and p-value
s2 <- 2*(cp_red1$loglik[2]-cp_red2$loglik[2])
1-pchisq(s2,1)


#reduced model 3
cp_red3<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth, data=aids)
cp_red3$loglik
#cp_red3

#likelihood ratio test and p-value
s3 <- 2*(cp_red2$loglik[2]-cp_red3$loglik[2])
1-pchisq(s3,1)


#reduced model 4
cp_red4<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth -strat2, data=aids)
cp_red4$loglik
#cp_red4

#likelihood ratio test and p-value
s4 <- 2*(cp_red3$loglik[2]-cp_red4$loglik[2])
1-pchisq(s4,1)

#reduced model 5
cp_red5<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth -strat2 -hemophil, data=aids)
cp_red5$loglik
#cp_red5

#likelihood ratio test and p-value
s5 <- 2*(cp_red4$loglik[2]-cp_red5$loglik[2])
1-pchisq(s5,1)

#reduced model 6
cp_red6<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth -strat2 -hemophil -sex, data=aids)
cp_red6$loglik
#cp_red6

#likelihood ratio test and p-value
s6 <- 2*(cp_red5$loglik[2]-cp_red6$loglik[2])
1-pchisq(s6,1)

#reduced model 7
cp_red7<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth -strat2 -hemophil -sex -id, data=aids)
cp_red7$loglik
cp_red7

#likelihood ratio
s7 <- 2*(cp_red6$loglik[2]-cp_red7$loglik[2])
1-pchisq(s7,1)

#reduced model 8
cp_red8<- coxph(Surv(time_d,censor_d)~.-time -censor -txgrp -ivdrug -priorzdv -raceth -strat2 -hemophil -sex -id, data=aids)
cp_red8$loglik
cp_red8


#likelihood ratio
s8 <- 2*(cp_red7$loglik[2]-cp_red8$loglik[2])
1-pchisq(s8,1)

```

To better understand how much the model fit changes with each different explanatory variable, we can use the graphical representation of the Aalen additive regression model. The Aalen model allows for time-varying covariate effects, while the Cox model allows only a common time-dependence through the baseline. In the Aalen model, we have the weighted comparisons of the crude estimate of the hazard rate of each group as compared to a baseline group, which here is defined as the estimate. As we can see, the selected explanatory variables in our model all have an inverse coefficient correlation with the baseline interceipt. The slope of an estimated cumulative regression function is positive when covariate increases and this fact correspond to an increasing hazard rate. On the other hand, if the slope is negative while the covariate increases, then this fact points to a decreasing hazard rate.

```{r}
library(ggfortify)
aids <- read.csv( "http://pages.pomona.edu/~jsh04747/courses/math150/AIDSdata.csv")

aa_fit <-aareg(Surv(time, censor) ~ cd4 + karnof+ priorzdv +hemophil +raceth +sex +tx +ivdrug,
               data = aids)

autoplot(aa_fit,xlab="Coefficient", ylab="Time") + labs(x = "time", y = "coefficient")


aa_fit2 <-aareg(Surv(time, censor) ~ cd4 + karnof+ tx , data = aids)

autoplot(aa_fit2) + labs(x = "time", y = "coefficient")

```

The Aalen model assumes that the cumulative hazard $H(t)$ for a subject can be expressed as $a(t)$ + X $B(t)$, where $a(t)$ is a time-dependent intercept term, X is the vector of covariates for the subject possibly time-dependent, and $B(t)$ is a time-dependent matrix of coefficients.

The plots show how the effects of the covariates change over time. 


#Patricia's "Something New": Power analysis using simulated survival data

Power analysis is an important aspect of experimental design. Power tells us how often we can correctly reject the null hypothesis. It is useful in helping us determine how large our sample size must be in order to correctly detect if there is an effect, with a certain level of confidence. Furthermore, it can help us determine the probability with which we will correctly detect an effect given that we have a known sample size. 
Overall power analysis is important when conducting experiments because without a high level of power, experiments and studies would not receive funding from research centers, such as the the NIH (National Institute of Health).


### 2. How it is relevant? How it relates to survival analysis/analysis at hand?
Power analysis relates to survival analysis because if power is large after comparing our data to the simulated survival data, this tells us that there is a high chance that we would reject the null in favor of the alternative (control versus treatment?)

### 3. Resources to learn about the topic.
Below are some of the resources I have begun to use to learn about creating simulations of survival curves and performing power analysis:

a). https://cran.r-project.org/web/packages/coxed/vignettes/simulating_survival_data.html
b). http://www.icssc.org/documents/advbiosgoa/tab%2026.00_survss.pdf


### Power Analysis code and simulation
```{r}
simdata <- sim.survdata(N=1000, T=100, num.data.frames=1, beta = c(0.01,0.07,0.3))
head(simdata$data,10)
simdata$betas
head(simdata$baseline,10)


#ggsurvplot(survfit(Surv(y,failed) ~ X1 + X2 + X3, data = simdata$data))
model <- coxph(Surv(y, failed) ~ X1 + X2 + X3, data = simdata$data)

library(dplyr)
library(broom)
model %>% tidy()

set.seed(1234)
n.reps <- 100
simoutput <- c()
for(i in 1:n.reps){
  simdata <- sim.survdata(N=851, T=362, num.data.frames=1, censor= 0.9764,xvars=4, mu=m, sd=s, beta = c(-0.867409, -0.071620, -0.016659, 0.073674))
  model <- coxph(Surv(y, failed) ~ X1 + X2 + X3 +X4, data = simdata$data)
  simoutput <- rbind(simoutput, cbind(rep = rep(i, 4), model %>% tidy()))
  
}

#simoutput

#sum(which(simoutput$p.value < 0.05))
sum(simoutput$p.value < 0.05)

#simoutput%>%filter(term=="X1")%>%summarize(sum(p.value<0.05))

simoutput%>%dplyr::filter(term=="X1")%>%dplyr::summarize(sum(p.value<0.05))

simoutput%>%dplyr::filter(term=="X2")%>%dplyr::summarize(sum(p.value<0.05))

simoutput%>%dplyr::filter(term=="X3")%>%dplyr::summarize(sum(p.value<0.05))

simoutput%>%dplyr::filter(term=="X4")%>%dplyr::summarize(sum(p.value<0.05))


str(simdata$data)
m <-c(mean(aids$tx), mean(aids$karnof), mean(aids$cd4), mean(aids$age))
s <-c(sd(aids$tx), sd(aids$karnof), sd(aids$cd4), sd(aids$age))

m
s
simoutput%>%dplyr::filter(term=="X4")%>%dplyr::select(estimate)%>%hist(breaks=200)


temp <- sim.survdata(N=851, num.data.frames = 1, xvars = 4, beta = c(-0.867409, -0.071620, -0.016659, 0.073674), censor = 0.9764, mu=m,sd=s)
str(temp$data)
hist(temp$data$X3)
library(FDRsampsize)
library(powerSurvEpi)
```

```{r}
### POWER ANALYSIS AND SIMULATION ###
#set.seed(1234)
#n.reps <- 100
#simoutput2 <- c()
#for(i in 1:n.reps){
  #simdata2 <- sim.survdata(N=851, T=362, num.data.frames=1, censor= 0.2, 
                          #X=aids[,c(6,13,14,16)] ,
                          #beta = c(-0.867409, -0.071620, -0.016659, 0.073674))
  #model <- coxph(Surv(y, failed) ~ tx + karnof, data = simdata2$data)
  #simoutput2 <- rbind(simoutput2, cbind(rep = rep(i, 2), model %>% tidy()))
  
#}

#simoutput2%>%dplyr::filter(term=="tx")%>%dplyr::summarize(sum(p.value<0.05))

#simoutput2%>%dplyr::filter(term=="karnof")%>%dplyr::summarize(sum(p.value<0.05))

#simoutput2%>%dplyr::filter(term=="cd4")%>%dplyr::summarize(sum(p.value<0.05))

#simoutput2%>%dplyr::filter(term=="age")%>%dplyr::summarize(sum(p.value<0.05))

#str(simdata2$data)
```



# Juste's "Something New": The Schoenfeld Residuals for the Cox PH model

  Cox proportional hazards (PH) model is considered a great way to identify combined effects of several covariates on the relative risk (hazard). This model assumes that the hazards of the different strata formed by the levels of the covariates are proportional. This proportional hazards assumption is particularly important and can be tested via three different classes of tests. The first class is focused on the piece-wise estimation of models for subsets of data defined by stratification of time. The second one considers the interactions between covariates and some function of time. Final, third one is based on examinations of regression residuals. The Schoenfeld Residuals are a part of the third class of proportional hazard assumption testing and I will be exploring it in order to be able to eradicate a method for testing for the PH assumption in the current and future data set analyses. This topic is particularly important in relation to survival analysis since it provides an idea of whether the model is appropriate for the data set at hand and whether some covariates should be considered as variants of time in order to supply the best model for prediction of proportional hazards.
  Taking a completely new model of analyzing survival data is particularly difficult since the mathematical derivations and notations are also very varied from what we have seen in class. Although, I do remember some of the ideas behind parametric functions, their applications to statistical models are much more challenging than I have expected. Therefore, it will require me a lot of time and extensive research to be able to understand and learn how to apply this model to our data and other instances of survival analysis.

### 3. Resources to learn about the topic.

I have been researching articles and scientific journals that provide insights into the Schoenfeld residuals and their use in the Cox PH model. 
Sources include: 

1. https://onlinelibrary.wiley.com/doi/full/10.1111/ajps.12176
2. https://rstudio-pubs-static.s3.amazonaws.com/39354_34153ff19e624116bd2fbdec7d2534aa.html 





### Explanation of the Theory Behind Schoenfeld Residuals

Let $z_{ij}(t)$ be the $j^{th}$ covariate of the $i^{th}$ unit, where $i=1,2,...,n$ and $j=1,2...,p$

This notation indicates that $z_{ij}$ is allowed to vary as a function of the time scale.

1) As we know from lecture, the Cox PH model assumes that $h(t)$ of the $i^{th}$ individual satisfies: 

* $h_i(t)=h_0(t)e^{z_i(t)\beta}$ where: 
  + $h_0$ -> baseline hazard
  + $z_i(t)$ -> 1 x $p$ vector of covariates for unit $i$ each of which can be time fixed or time-varying.

2) However, another possibility has been presented by Therneau and Granbsh in 2000, where they proposed an idea that there could be an alternative to the current Cox model, where the coefficient of the estimate could also be varying as a function of time.

> The new hazard function would look like this: $h_i(t)=h_0(t)e^{z_i(t)\beta(t)}$

Therefore, in order to examine thee two models in a case when $\beta=\beta(t)$ requires a residual analysis that could indicate whether a model should consider a covariate as a variable with time.

***
Due to the fact that that some observations might be censored and in particular, regarding the Cox PH model, the baseline hazard is not estimated, in order to analyse the residuals a particular score process. The risk score for unit $i$ at time $t$ is thought to be $r_i(t)=e^{z_i(t)\beta}$, where $Y_i(t)$ is the indicator function and $Y_i(t)=1$ indicates a point in which $i$ is under risk and thus observation and it is equal to 0 in other occasions.

***

The Schoenfeld residuals are given by the equations:

1. $s_k=Z_{(k)}-\frac{\sum_iY_i(t_k)r_i(t_k)Z_i(t_k)}{\sum_iY_i(t_k)r_i(t_k)}$
2. $s_k=Z_{(k)}-\bar{z}(\hat{\beta},t_k)$

In this case, the $Z(k)$ is the covariate vector of the particular unit that is experiencing the event at time $k$; $\hat{\beta}$ is the estimate of $\beta$ and $\bar{z}(\hat{\beta},t_k)$ is the weighted mean of covariate values.

Furthermore, the weighted variance can be represented by the derived equation at the $k^{th}$ time as

$V(\beta,t_k)=\sum_iY_i(t_k)r_i(t_k)Z_i(t_k)-\bar{z}(\hat{\beta},t_k)'Z_i(t_k)-\frac{\bar{z}(\hat{\beta},t_k)}{\sum_iY_i(t_k)r_i(t_k)}$

From this, we can scale the Schoenfeld residuals by $V(\beta,t_k)$ of X at $t_k$ via the equation:

$s^*_k=V^{-1}(\hat{\beta},t_k)s_k$

The scaled Schoenfeld residuals can also be defined as follows:

$s^*_k=m\sum^d_{k=1}V(\hat{\beta},t_k)s_k$

here, $m$ is the total number of deaths in the data set.

Following the calculations, the residuals are plotted against time in order to test the proportional hazards assumption. If the assumption is correct, the residuals should be fitting around the line centered at zero (y=0). The further away this predicted line is form the horizontal of (y=0) the more likely one is to call the PH assumption to question and determine whether it is met through the model.

***
> To go a little deeper into the analysis of the resiaul calculation, one can look at the calculations of the test statistic for this residual mdoel.

By producing a least squares slope of regression and assuming a relationship between $s^*_{kj}$ and $t_{kj}$ or some function $g(t_k)$ allows to derive a test statistic for the proportional hazards assumption in regards to the $j^{th}$ covariate, which is given by:

$T_j=\frac{[\sum^d_{k=1}(g(t_k)-\hat{g})s^8_{kj}]^2}{dI^{jj}\sum^d_{k=1}(g(t_k)-\hat{g})^2}$

Here, the distribution is asymptotically as $X^2(1)$ stating the null hypothesis that the relationship between the covariate, in this case $j$ and the event time follows the assumption of PH.

***

> Interpretation of Schoenfeld Residuals from plots in R and the p-values presented.

The y-axis of the Schoenfeld residuals graph can be interpreted as the log of the hazard ratio for the explanatory variable-- the coefficient in Coxâ€™s model if it were allow to vary over time. If the graph is flat, then the PH assumption is adequate. Furthermore, the Schoenfeld residuals are independent of time. A plot that shows a non-random pattern against time is evidence of violation of the PH assumption. The PH assumption is supported when there's a non-significant relationship between residuals and time.
### HIV Data Cox PH model analysis using Schoenfeld Residuals

Schoenfeld Residuals applied to our best Cox PH model for AIDS data where, we have an additive model of explanatory variables: baseline CD4 count, iv drug use history, and karnofsky performance scale score:
```{r}
cph_tx <- coxph(Surv(time,censor)~ tx, data = aids)
cph_tx
zph_tx <- cox.zph(cph_tx)
zph_tx
ggcoxzph(zph_tx, point.size = 1, point.shape = 19)
ggcoxdiagnostics(cph_tx, type="schoenfeld")

cph_cd4 <- coxph(Surv(time,censor)~ cd4, data = aids)
cph_cd4
zph_cd4 <- cox.zph(cph_cd4)
zph_cd4
ggcoxzph(zph_cd4, point.size = 1, point.shape = 10)
ggcoxdiagnostics(cph_cd4, type="schoenfeld")

cph_k <- coxph(Surv(time,censor)~ karnof, data = aids)
cph_k
zph_k <- cox.zph(cph_k)
zph_k
ggcoxzph(zph_k, point.size = 1, point.shape = 10)
ggcoxdiagnostics(cph_k, type="schoenfeld")
```

Using the best determined Cox PH model for our data, we can look at the Schoenfeld residuals to determine if the PH assumption is met. Via the function "ggcoxzph()"", which produces, for each covariate, graphs of the scaled Schoenfeld residuals against the transformed time. Here, the solid line is a smoothing spline fit to the plot, with the dashed lines representing a +/- 2-standard-error. from these graphs, we don't see any patterns or significance of the residual fit regarding the graphs of the covariates with time. Therefore, the assumption of proportional hazards seems to be supported for the covariates: baseline CD4 count, iv drug use history, and karnofsky performance scale score.

Using the ggcoxdiagnostics() function we can provide another graphic representation of the residual distribution in regards to the covariates with time. Here, we also see that there's no particular pattern of the residuals around the line of fit, therefore again, we can state that the PH assumption has been met.

References:
1. http://www.ukm.my/jsm/pdf_files/SM-PDF-46-3-2017/15%20Aditif%20Aalen.pdf 
